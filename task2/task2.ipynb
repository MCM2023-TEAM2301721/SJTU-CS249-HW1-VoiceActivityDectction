{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.mixture import GaussianMixture\n",
    "import wave\n",
    "import math\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.io import wavfile\n",
    "import python_speech_features as psf\n",
    "import vad_utils as vad\n",
    "import evaluate as eva\n",
    "\n",
    "\"\"\"\n",
    "已知音频文件采样率均为16kHz\n",
    "取帧长度32ms : frame_length = 512\n",
    "取帧移8ms : step = 128\n",
    "\"\"\"\n",
    "\n",
    "# 路径\n",
    "dev_wav_path = \"../vad/wavs/dev\"\n",
    "train_wav_path = \"../vad/wavs/train\"\n",
    "label_path = \"../vad/data\"\n",
    "\n",
    "# 读label文件\n",
    "dev_label_data = vad.read_label_from_file(label_path + \"/dev_label.txt\")\n",
    "train_label_data = vad.read_label_from_file(label_path + \"/train_label.txt\")\n",
    "print(\"Read label success\")\n",
    "\n",
    "# 读取文件夹\n",
    "dev_files = os.listdir(dev_wav_path)\n",
    "train_files = os.listdir(train_wav_path)\n",
    "print(\"Read files success\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# total_frames = 0\n",
    "\n",
    "voice_features = []\n",
    "nonvoice_features = []\n",
    "print(\"List initialize success\")\n",
    "\n",
    "for file in train_files:\n",
    "    # 读取当前wav的label\n",
    "    current_label_data = train_label_data[file[0:-4]]\n",
    "    # 读取当前wav文件\n",
    "    sample_rate, wav_data = wavfile.read(train_wav_path + \"/\" + file)\n",
    "\n",
    "    print(\"Processing \" + train_wav_path + \"/\" + file)\n",
    "\n",
    "    wav_vector = psf.base.mfcc(wav_data, 16000, 0.032, 0.008)\n",
    "\n",
    "    # 计算帧数\n",
    "    L = len(wav_data)\n",
    "    num_of_steps = np.asarray(np.ceil((L - 512) / 128) + 1, dtype=int)\n",
    "\n",
    "    # total_frames += num_of_steps\n",
    "\n",
    "    # print(num_of_steps)\n",
    "    # print(len(wav_vector))\n",
    "\n",
    "    # 时间轴\n",
    "    time = np.zeros(num_of_steps)\n",
    "    for i in range(num_of_steps):\n",
    "        time[i] = (i * 128 + 256) / 16000\n",
    "    \n",
    "    # 补零\n",
    "    current_label_data = train_label_data[file[0:-4]]\n",
    "    current_label_data = list(current_label_data) + list(\n",
    "        np.zeros(len(time) - len(current_label_data))\n",
    "    )\n",
    "\n",
    "    for i in range(num_of_steps):\n",
    "        if current_label_data[i] == 1:\n",
    "            # 标记为语音片段的帧\n",
    "            voice_features.append(wav_vector[i])\n",
    "        else:\n",
    "            # 标记为非语音片段的帧\n",
    "            nonvoice_features.append(wav_vector[i])\n",
    "    \n",
    "    # print(wav_vector)\n",
    "    print(np.array(wav_vector).shape)\n",
    "    # break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 语音片段\n",
    "print(len(voice_features))\n",
    "# voice_features = np.vstack((voice_features, voice_vector))\n",
    "# 非语音片段\n",
    "print(len(nonvoice_features))\n",
    "# nonvoice_features = np.vstack((voice_features, nonvoice_vector))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nTraining voice GMM...\\n\")\n",
    "voice_gmm = GaussianMixture(n_components=26)\n",
    "voice_gmm.fit(voice_features)\n",
    "print(\"Voice GMM converged: \")\n",
    "print(voice_gmm.converged_)\n",
    "\n",
    "print(\"\\nTraining voice GMM...\\n\")\n",
    "nonvoice_gmm = GaussianMixture(n_components=26)\n",
    "nonvoice_gmm.fit(nonvoice_features)\n",
    "print(\"Nonvoice GMM converged: \")\n",
    "print(nonvoice_gmm.converged_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_acc(prediction, actual):\n",
    "    \"\"\"\n",
    "    input:\n",
    "        prediction 预测list eg.[0,0,1,0,...,1,0]\n",
    "        actual 从实际label文件中读取的list\n",
    "    return:\n",
    "        acc accuracy\n",
    "    \"\"\"\n",
    "    total_frame = len(actual)\n",
    "    correct_frame = 0\n",
    "\n",
    "    for i in range(total_frame):\n",
    "        if prediction[i] == actual[i]:\n",
    "            correct_frame += 1\n",
    "    acc = correct_frame / total_frame\n",
    "\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    /dev\n",
    "    开发集\n",
    "    所有不随循环消亡的变量均带dev_前缀\n",
    "\"\"\"\n",
    "\n",
    "# 创建输出文件\n",
    "dev_output = open(\"dev_output.txt\", \"w\")\n",
    "\n",
    "# 用于计算AUC、EER、ROC等指标的变量，不随循环消亡\n",
    "dev_reserve_for_cal = []\n",
    "dev_label_for_cal = []\n",
    "\n",
    "# 读取开发集label，返回dict\n",
    "dev_label_data = vad.read_label_from_file(label_path + \"/dev_label.txt\")\n",
    "\n",
    "for file in dev_files:\n",
    "    sample_rate, wav_data = wavfile.read(dev_wav_path + \"/\" + file)\n",
    "\n",
    "    print(\"Processing \" + dev_wav_path + \"/\" + file)\n",
    "\n",
    "    vectors = psf.base.mfcc(wav_data, sample_rate, 0.032, 0.008)\n",
    "\n",
    "    # # 计算两个模型下的predict\n",
    "    # voice_predict = np.array(voice_gmm.predict(vectors))\n",
    "    # non_predict = np.array(nonvoice_gmm.predict(vectors))\n",
    "\n",
    "    # 计算两个模型下的scores\n",
    "    voice_score_samples = np.array(voice_gmm.score_samples(vectors))\n",
    "    non_score_samples = np.array(nonvoice_gmm.score_samples(vectors))\n",
    "\n",
    "    # print(voice_score_samples)\n",
    "    # print(non_score_samples)\n",
    "    # print(len(voice_score))\n",
    "    # print(len(non_score))\n",
    "\n",
    "    # 计算帧数，帧数、两个predict的长度应都相同\n",
    "    L = len(wav_data)\n",
    "    num_of_steps = np.asarray(np.ceil((L - 512) / 128) + 1, dtype=int)\n",
    "    # print(num_of_steps)\n",
    "\n",
    "    # 时间轴\n",
    "    time = np.zeros(num_of_steps)\n",
    "    for i in range(num_of_steps):\n",
    "        time[i] = (i * 128 + 256) / 16000\n",
    "\n",
    "    # 补零\n",
    "    current_label_data = dev_label_data[file[0:-4]]\n",
    "    current_label_data = list(current_label_data) + list(\n",
    "        np.zeros(len(time) - len(current_label_data))\n",
    "    )\n",
    "    # print(len(current_label_data))\n",
    "\n",
    "    # 保存label\n",
    "    for i in range(len(current_label_data)):\n",
    "        dev_label_for_cal.append(current_label_data[i])\n",
    "    # print(len(dev_label_for_cal))\n",
    "    \n",
    "    # 定义并初始化保存单个wav文件中各帧prediction的list\n",
    "    result = []\n",
    "\n",
    "    # 取大\n",
    "    for i in range(len(voice_score_samples)):\n",
    "        if voice_score_samples[i] >= non_score_samples[i]:\n",
    "            result.append(1)\n",
    "            dev_reserve_for_cal.append(1)\n",
    "        else:\n",
    "            result.append(0)\n",
    "            dev_reserve_for_cal.append(0)\n",
    "\n",
    "    dev_label = []\n",
    "    dev_label = vad.prediction_to_vad_label(result)\n",
    "\n",
    "    dev_output.write(file[0:-4] + \" \" + dev_label + \"\\n\")\n",
    "\n",
    "dev_output.close()\n",
    "print(\"\\nComplete!\\nResult file generated as dev.txt\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nCalculating AUC, EER, TPR, FPR, Threshold of dev dataset...\\n\")\n",
    "auc, eer, tpr, fpr, thres = eva.get_metrics(dev_reserve_for_cal, dev_label_for_cal)\n",
    "print(\"AUC = \", auc)\n",
    "print(\"EER = \", eer)\n",
    "print(\"TPR = \", tpr)\n",
    "print(tpr.shape)\n",
    "print(\"FPR = \", fpr)\n",
    "print(fpr.shape)\n",
    "# print(\"Threshold = \", thres)\n",
    "\n",
    "dev_acc = get_acc(dev_reserve_for_cal, dev_label_for_cal)\n",
    "print(\"ACC = \", dev_acc)\n",
    "\n",
    "plt.plot(fpr, tpr)\n",
    "plt.xlabel(\"FPR\")\n",
    "plt.ylabel(\"TPR\")\n",
    "plt.title(\"ROC\")\n",
    "plt.savefig(\"dev_ROC.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    /train\n",
    "    训练集\n",
    "    所有不随循环消亡的变量均带train_前缀\n",
    "\"\"\"\n",
    "\n",
    "# 创建输出文件\n",
    "train_output = open(\"train_output.txt\", \"w\")\n",
    "\n",
    "# 用于计算AUC、EER、ROC等指标的变量，不随循环消亡\n",
    "train_reserve_for_cal = []\n",
    "train_label_for_cal = []\n",
    "\n",
    "# 读取开发集label，返回dict\n",
    "train_label_data = vad.read_label_from_file(label_path + \"/train_label.txt\")\n",
    "\n",
    "for file in train_files:\n",
    "    sample_rate, wav_data = wavfile.read(train_wav_path + \"/\" + file)\n",
    "\n",
    "    print(\"Processing \" + train_wav_path + \"/\" + file)\n",
    "\n",
    "    vectors = psf.base.mfcc(wav_data, sample_rate, 0.032, 0.008)\n",
    "\n",
    "    # # 计算两个模型下的predict\n",
    "    # voice_predict = np.array(voice_gmm.predict(vectors))\n",
    "    # non_predict = np.array(nonvoice_gmm.predict(vectors))\n",
    "\n",
    "    # 计算两个模型下的scores\n",
    "    voice_score_samples = np.array(voice_gmm.score_samples(vectors))\n",
    "    non_score_samples = np.array(nonvoice_gmm.score_samples(vectors))\n",
    "\n",
    "    # print(voice_score_samples)\n",
    "    # print(non_score_samples)\n",
    "    # print(len(voice_score))\n",
    "    # print(len(non_score))\n",
    "\n",
    "    # 计算帧数，帧数、两个predict的长度应都相同\n",
    "    L = len(wav_data)\n",
    "    num_of_steps = np.asarray(np.ceil((L - 512) / 128) + 1, dtype=int)\n",
    "    # print(num_of_steps)\n",
    "\n",
    "    # 时间轴\n",
    "    time = np.zeros(num_of_steps)\n",
    "    for i in range(num_of_steps):\n",
    "        time[i] = (i * 128 + 256) / 16000\n",
    "\n",
    "    # 补零\n",
    "    current_label_data = train_label_data[file[0:-4]]\n",
    "    current_label_data = list(current_label_data) + list(\n",
    "        np.zeros(len(time) - len(current_label_data))\n",
    "    )\n",
    "    # print(len(current_label_data))\n",
    "\n",
    "    # 保存label\n",
    "    for i in range(len(current_label_data)):\n",
    "        train_label_for_cal.append(current_label_data[i])\n",
    "    # print(len(train_label_for_cal))\n",
    "    \n",
    "    # 定义并初始化保存单个wav文件中各帧prediction的list\n",
    "    result = []\n",
    "\n",
    "    # 取大\n",
    "    for i in range(len(voice_score_samples)):\n",
    "        if voice_score_samples[i] >= non_score_samples[i]:\n",
    "            result.append(1)\n",
    "            train_reserve_for_cal.append(1)\n",
    "        else:\n",
    "            result.append(0)\n",
    "            train_reserve_for_cal.append(0)\n",
    "\n",
    "    train_label = []\n",
    "    train_label = vad.prediction_to_vad_label(result)\n",
    "\n",
    "    train_output.write(file[0:-4] + \" \" + train_label + \"\\n\")\n",
    "\n",
    "train_output.close()\n",
    "print(\"\\nComplete!\\nResult file generated as train.txt\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nCalculating AUC, EER, TPR, FPR, Threshold of train dataset...\\n\")\n",
    "auc, eer, tpr, fpr, thres = eva.get_metrics(train_reserve_for_cal, train_label_for_cal)\n",
    "print(\"AUC = \", auc)\n",
    "print(\"EER = \", eer)\n",
    "print(\"TPR = \", tpr)\n",
    "print(tpr.shape)\n",
    "print(\"FPR = \", fpr)\n",
    "print(fpr.shape)\n",
    "# print(\"Threshold = \", thres)\n",
    "\n",
    "train_acc = get_acc(train_reserve_for_cal, train_label_for_cal)\n",
    "print(\"ACC = \", train_acc)\n",
    "\n",
    "plt.plot(fpr, tpr)\n",
    "plt.xlabel(\"FPR\")\n",
    "plt.ylabel(\"TPR\")\n",
    "plt.title(\"ROC\")\n",
    "plt.savefig(\"train_ROC.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    test/\n",
    "    测试集\n",
    "    所有不随循环消亡的变量均带test_前缀\n",
    "\"\"\"\n",
    "\n",
    "# 创建输出文件\n",
    "test_output = open(\"test_output.txt\", \"w\")\n",
    "\n",
    "# 定义测试集语音路径\n",
    "test_wav_path = \"../vad/wavs/test\"\n",
    "\n",
    "# 读取测试集文件夹\n",
    "test_files = os.listdir(test_wav_path)\n",
    "\n",
    "# 用于计算AUC、EER、ROC等指标的变量，不随循环消亡\n",
    "test_reserve_for_cal = []\n",
    "test_label_for_cal = []\n",
    "\n",
    "for file in test_files:\n",
    "    # 读取语音\n",
    "    sample_rate, wav_data = wavfile.read(test_wav_path + \"/\" + file)\n",
    "    print(\"Processing \" + test_wav_path + \"/\" + file)\n",
    "\n",
    "    # MFCC\n",
    "    vectors = psf.base.mfcc(wav_data, sample_rate, 0.032, 0.008)\n",
    "\n",
    "    # 计算帧数\n",
    "    L = len(wav_data)\n",
    "    num_of_steps = np.asarray(np.ceil((L - 512) / 128) + 1, dtype=int)\n",
    "\n",
    "    # 计算两个模型下的scores\n",
    "    voice_score_samples = np.array(voice_gmm.score_samples(vectors))\n",
    "    non_score_samples = np.array(nonvoice_gmm.score_samples(vectors))\n",
    "    \n",
    "    # 定义并初始化保存单个wav文件中各帧prediction的list\n",
    "    result = []\n",
    "\n",
    "    # 取大\n",
    "    for i in range(len(voice_score_samples)):\n",
    "        if voice_score_samples[i] >= non_score_samples[i]:\n",
    "            result.append(1)\n",
    "            test_reserve_for_cal.append(1)\n",
    "        else:\n",
    "            result.append(0)\n",
    "            test_reserve_for_cal.append(0)\n",
    "\n",
    "    # test_label是保存单个wav文件VAD label的list\n",
    "    test_label = []\n",
    "    test_label = vad.prediction_to_vad_label(result)\n",
    "    test_output.write(file[0:-4] + \" \" + test_label + \"\\n\")\n",
    "\n",
    "test_output.close()\n",
    "print(\"\\nComplete!\\nResult file generated as test_output.txt\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nCalculating AUC, EER, TPR, FPR, Threshold of test dataset...\\n\")\n",
    "auc, eer, tpr, fpr, thres = eva.get_metrics(dev_reserve_for_cal, dev_label_data)\n",
    "print(\"AUC = \", auc)\n",
    "print(\"EER = \", eer)\n",
    "print(\"TPR = \", tpr)\n",
    "print(\"FPR = \", fpr)\n",
    "print(\"Threshold = \", thres)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "40a569c1bc2f82f03fa31a1ae55d86f650bd11a45524a0bb81f49cd9660e67b3"
  },
  "kernelspec": {
   "display_name": "Python 3.10.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
